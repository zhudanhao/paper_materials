{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2994da48-fd08-4d9c-92d2-3fec84658c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-06-28 08:31:14,387\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fde818e7-3c81-434e-b2e0-d5e7ed751cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-28 08:31:15 llm_engine.py:75] Initializing an LLM engine (v0.4.0) with config: model='Qwen-main/input_qwen/qwen1.5-7B', tokenizer='Qwen-main/input_qwen/qwen1.5-7B', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-28 08:31:15 selector.py:45] Cannot use FlashAttention because the package is not found. Please install it for better performance.\n",
      "INFO 06-28 08:31:15 selector.py:21] Using XFormers backend.\n",
      "INFO 06-28 08:31:20 model_runner.py:104] Loading model weights took 14.3919 GB\n",
      "INFO 06-28 08:31:22 gpu_executor.py:94] # GPU blocks: 6844, # CPU blocks: 512\n",
      "INFO 06-28 08:31:24 model_runner.py:791] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 06-28 08:31:24 model_runner.py:795] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 06-28 08:31:27 model_runner.py:867] Graph capturing finished in 4 secs.\n"
     ]
    }
   ],
   "source": [
    "# 初始化 vLLM 的离线推理引擎，这里选择的是 \"/root/chinese-llama2\" 模型\n",
    "# model_path = 'Qwen-main/output_qwen/Final/Qwen1.5_y_3e-5'\n",
    "model_path = 'Qwen-main/input_qwen/qwen1.5-7B'\n",
    "llm = LLM(model=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94f5bd50-0cd5-472c-a77f-3d75d671c7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785\n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "data_path = \"Qwen-main/data/eval_new.json\"\n",
    "\n",
    "# 读取json文件内部的内容\n",
    "f = open(data_path)\n",
    "content = f.read()\n",
    "before_prompts = json.loads(content)\n",
    "\n",
    "prompts = []\n",
    "y = []\n",
    "for i in range(len(before_prompts)):\n",
    "    prompt = before_prompts[i]['conversations'][0]['value'] + ':'\n",
    "    prompts.append(prompt)\n",
    "    y.append(before_prompts[i]['conversations'][1]['value'])\n",
    "\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "970dbdc9-2033-4713-9ad7-98ca976b19ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmts = []\n",
    "for i in range(len(prompts)):\n",
    "    pmt = \"摘要案例为为：{}, 请按照案例格式回答下面问题：{}\".format(y[0], prompts[i])\n",
    "    pmts.append(pmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "831ba11b-f323-4c6f-a5b8-f41fb684480f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 785/785 [09:49<00:00,  1.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# 定义采样参数，temperature 控制生成文本的多样性，top_p 控制核心采样的概率\n",
    "sampling_params = SamplingParams(top_p=0.5, max_tokens=900)\n",
    "output = llm.generate(pmts, sampling_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42601322-9dbb-4342-9edb-b805fb41c82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 原告广州摩安珂服饰有限公司与被告现想商贸（上海）有限公司、现想商贸（上海）有限公司深圳第二分公司租赁合同纠纷一案。原告提出诉求：判令两被告向原告支付拖欠的款项及利息；两被告对上述债务承担连带清偿责任。被告未到庭，未提交书面意见及证据。经查明原告与被告现想公司深圳第二分公司签署的《专柜联营（租赁）合作协议》和《补充协议》均为双方的真实意思表示，内容未违反法律及行政法规的强制性规定，为有效合同。被告现想公司深圳第二分公司是现想公司设立的分支机构，在法律上、经济上没有独立性，仅仅是总公司的附属机构，不具有企业法人资格，其民事责任由总公司承担。依照《中华人民共和国合同法》第四十四条第一款、第六十条第一款、第一百零七条、第一百零九条、第一百一十二条，《中华人民共和国公司法》第十四条第一款以及《中华人民共和国民事诉讼法》第六十四条第一款、第一百四十二条的规定，判决: 一、被告现想商贸（上海）有限公司深圳第二分公司应向原告广州摩安珂服饰有限公司支付欠款及利息。 二、被告现想商贸（上海）有限公司对被告现想商贸（上海）有限公司深圳第二分公司不能清偿部分承担补充清偿责任。 三、驳回原告广州摩安珂服饰有限公司其他诉讼请求。'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0].outputs[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb587799-7c83-48c7-a05e-d710be8cc797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "整合完成\n"
     ]
    }
   ],
   "source": [
    "## 将推理到的数据和原数据整合\n",
    "predict_y = []\n",
    "for i in range(len(output)):\n",
    "    dict_={}\n",
    "    dict_['y'] = y[i]\n",
    "    if(len(output[i].outputs[0].text)!=0):\n",
    "        dict_['pred'] = output[i].outputs[0].text\n",
    "    else:\n",
    "        dict_['pred'] = \"本次生成失败\"\n",
    "    predict_y.append(dict_)\n",
    "    \n",
    "print(\"整合完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5043eb49-2985-473f-b9a6-aadebaaa8c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = \"Qwen-main/data/eval_data/JI_FEW_0628_V2340.json\"\n",
    "json_file = open(json_file_path, mode='w', encoding='utf-8')\n",
    "json.dump(predict_y, json_file, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60174073-2ff7-4fd4-a45a-7bea81235abb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
